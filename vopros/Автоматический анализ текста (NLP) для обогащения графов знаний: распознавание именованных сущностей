Граф знаний можно наполнять не только вручную, но и автоматически – за счет анализа текстов на естественном языке. Один из первых и ключевых этапов такого анализа – распознавание именованных сущностей (Named Entity Recognition, NER).
Именованная сущность (named entity) – это слово или фраза в тексте, обозначающая уникальный объект реального мира: например, имя собственного лица (Персона), название организации, географическое название, название продукта, даты, денежные суммы и т.д.
Задача NER заключается в том, чтобы автоматически найти в тексте упоминания таких сущностей и классифицировать их по типам (персона, локация, организация, и т.п.).
Например, в предложении: «Илон Маск основал компанию SpaceX в США в 2002 году.» – NER должна определить, что "Илон Маск" – это Person, "SpaceX" – Organization, "США" – Location, "2002" – Date.
аспознавание именованных сущностей – необходимый шаг для преобразования неструктурированных текстовых данных в семантический граф знаний. Ведь прежде чем добавить факты в граф, нужно извлечь из текста сущности (узлы графа) и понять,
какие именно реальные объекты они обозначают. Как работает NER: Современные системы используют модели машинного обучения (часто нейросети, такие как Bi-LSTM с CRF или трансформеры типа BERT), обученные на размеченных корпусах.
Эти модели анализируют контекст слов и решают, какие из них являются частями именованных сущностей и какого типа. Выход обычно – разметка каждого слова/токена специальными метками (например, BIO-схема: B-PER для начала имени персоны, 
I-PER для продолжения, O – не часть сущности). Также есть правила (регулярные выражения) для простых случаев: шаблоны для дат, форматы чисел, валют, которые выделяются по паттернам.
Пример:
Текст: "Игрок А отбил 10 мячей и выиграл кубок главного матча в Пекине в 2016 году."
NER-аннотация может выглядеть так:
"Игрок А" – [B-PER] [I-PER] (субъект, Персона)
"10" – [B-NUM] (число, количество)
"кубок" – (обычное слово, не сущность – возможно B-MISC, если трофей как уникальное название)
"главного матча" – (скорее всего не именованная сущность, обычное описание)
"Пекине" – [B-LOC] (место)
"2016" – [B-DATE] (время)
То есть система выделила: сущность типа Person ("Игрок А"), Numeric ("10"), Location ("Пекин"), Date ("2016")
Почему NER важен для графов знаний:
Идентификация узлов графа: Когда из текста извлекаются факты, нужно знать, кто и что участвует во взаимоотношениях. NER находит кандидатов на узлы. Например, чтобы внести факт "Илон Маск – основатель – SpaceX" в граф, надо сначала обнаружить "Илон Маск" и "SpaceX"
как именованные сущности (Person и Organization). Связка с существующими сущностями (Entity Linking): NER – это первый шаг. Следующий (не в вопросе, но примечание) – Named Entity Linking (NEL), привязка распознанной строки к конкретному объекту в базе знаний
(например, "Илон Маск" -> элемент Q… в Wikidata). Без корректного NER linking невозможен, потому что сначала надо понять границы имени. Обогащение словарей и онтологий: Результаты NER могут пополнить ваш граф новыми узлами (если система встретила новую сущность, которой еще нет в БЗ).
Например, в новостях упомянули новую компанию – NER её выделит, и можно добавить узел с этим именем (возможно, пока минимально – класс Organization). Фильтрация важной информации: В тексте много слов, но для базы знаний интересны в первую очередь сущности и отношения между ними.
NER решает первую задачу – отфильтровать имена собственные от общей лексики. Это резко сужает фокус: вместо всего текста алгоритмы далее работают с выявленными сущностями и окружающим их контекстом для извлечения отношений.
Классификационные схемы: Классическая разбивка – PER (person), ORG (organization), LOC (location), MISC (прочие, включая события, произведения и т.д.). Но бывают и расширенные (например, GPE – геополитическая единица, FAC – сооружения, PRODUCT, EVENT и т.д.).
Выбор типов зависит от потребностей БЗ: например, медицинская БЗ захочет распознавать лекарственные препараты, заболевания, гены – это тоже named entities, просто специфичные домены. Качество распознавания: Современные модели могут достигать точности ~90%+ на новостных текстах для
основных классов. Но всегда есть сложности:
